# ğŸš¦ RAG API â€“ Sistema de RecuperaciÃ³n Aumentada con Contexto, Feedback y ClasificaciÃ³n SemÃ¡ntica

Esta API implementa un **sistema RAG (Retrieval-Augmented Generation)** especializado en **leyes de trÃ¡nsito de Bolivia**, con caracterÃ­sticas avanzadas como:

* Vector store persistente con **ChromaDB**
* DetecciÃ³n de cambios en el archivo fuente con **hash MD5**
* ClasificaciÃ³n automÃ¡tica de continuidad de contexto mediante **LLM**
* RecuperaciÃ³n semÃ¡ntica mediante **embeddings OpenAI**
* Sistema de **feedback con aprendizaje continuo**
* Compatibilidad nativa con **Flutter** mediante CORS
* Manejo de conversaciones basadas en contexto y multiconsulta

La API es construida en **Flask + LangChain + OpenAI + ChromaDB**.

---

# ğŸ“ Estructura general

```
project/
 â”œâ”€ app.py                 # API principal (Flask)
 â”œâ”€ datoscompletos.txt     # Base textual de leyes (editable)
 â”œâ”€ filtro.py              # NormalizaciÃ³n de palabras
 â”œâ”€ contextcache.py        # Manejo de historial
 â”œâ”€ feedback.py            # DB SQLite para feedback
 â”œâ”€ chroma_db/             # Embeddings persistentes
 â”œâ”€ feedback.db            # Base de datos SQLite
 â””â”€ .env                   # Variables de entorno
```

---

# âš™ï¸ 1. ConfiguraciÃ³n previa

## 1.1 Variables de entorno (`.env`)

Crea un archivo:

```
OPENAI_API_KEY=tu_api_key
RAG_FILE_PATH=datoscompletos.txt
RAG_PERSIST_DIR=chroma_db
RAG_CHUNK_SIZE=500
RAG_CHUNK_OVERLAP=50
FEEDBACK_DB=feedback.db
```

---

# ğŸš€ 2. Inicializar el sistema

Antes de hacer consultas, debes inicializar la base vectorial:

### Endpoint

```
POST /api/initialize
```

### Respuesta esperada

```json
{
  "status": "success",
  "message": "RAG system initialized successfully",
  "time_taken": "3.42 seconds"
}
```

Esto:

* Carga el archivo `datoscompletos.txt`
* Lo divide en chunks
* Genera embeddings con OpenAI
* Guarda todo en `chroma_db/`

Si ya existe un hash igual, no regenera embeddings.

---

# ğŸ” 3. BÃºsqueda y generaciÃ³n de respuesta

### Endpoint

```
POST /api/search
```

### Body requerido

```json
{
  "query": "Â¿CuÃ¡l es la sanciÃ³n por no usar casco?",
  "k": 5,
  "oldquestion": "",
  "oldresponsefull": "",
  "summaries": []
}
```

## Campos:

| Campo             | DescripciÃ³n                             |
| ----------------- | --------------------------------------- |
| `query`           | Pregunta del usuario                    |
| `k`               | Cantidad de documentos a recuperar      |
| `oldquestion`     | Pregunta anterior (si hay conversaciÃ³n) |
| `oldresponsefull` | Respuesta anterior completa             |
| `summaries`       | Historial reducido de la conversaciÃ³n   |

La API automÃ¡ticamente:

* filtra palabras (`filtro_palabras`)
* detecta si es una **continuaciÃ³n del contexto**
* usa embeddings y clasificaciÃ³n LLM

---

## Respuesta tÃ­pica

```json
{
  "status": "success",
  "query": "Â¿CuÃ¡l es la sanciÃ³n por no usar casco?",
  "results": [...],
  "result_count": 5,
  "response": "SegÃºn el ArtÃ­culo 92...",
  "response_id": "9dc3a1f7b1...",
  "isnewcontext": true
}
```

---

# 4. Modo "ContinuaciÃ³n de contexto"

Cuando se envÃ­a:

```json
"oldquestion": "Â¿QuÃ© documentos debo llevar?",
"oldresponsefull": "Debes portar licencia...",
```

La API detecta si la nueva pregunta **estÃ¡ relacionada** usando un clasificador LLM interno.

Si estÃ¡ en contexto:

âœ” amplÃ­a la consulta combinando ambas preguntas
âœ” aumenta `k` automÃ¡ticamente
âœ” genera una respuesta basada en contexto histÃ³rico

---

# 5. Enviar feedback de usuario

La API aprende usando un sistema de retroalimentaciÃ³n que se guarda en SQLite (`feedback.db`).

### Endpoint

```
POST /api/feedback
```

### Body

```json
{
  "query": "Â¿CuÃ¡l es la sanciÃ³n por no usar casco?",
  "response": "SegÃºn el ArtÃ­culo 92...",
  "rating": 5,
  "contexts": ["uso de casco", "seguridad vial"]
}
```

### Respuesta

```json
{
  "status": "success",
  "message": "Feedback (rating: 5) saved successfully"
}
```

El feedback es usado para:

* Ajustar estilo de respuesta
* Aprender patrones positivos/negativos
* Mejorar la precisiÃ³n futura

---

# 6. EstadÃ­sticas de feedback

### Endpoint

```
GET /api/feedback/stats
```

Respuesta:

```json
{
  "status": "success",
  "stats": {
    "total_feedback": 12,
    "avg_rating": 4.6,
    "most_common_topics": ["casco", "licencia"]
  }
}
```

---

# 7. Health Check

### Endpoint

```
GET /api/health
```

Respuesta:

```json
{
  "status": "ok",
  "service": "RAG API",
  "config": {
    "file_path": "datoscompletos.txt",
    "chunk_size": 500
  },
  "feedback_stats": {...}
}
```

---

# 8. EjecuciÃ³n local

Instalar dependencias:

```
pip install -r Requirements.txt
```

Levantar API:

```
python main4.py
```

---
# 9. TecnologÃ­as utilizadas

* **Flask** â€“ API backend
* **OpenAI GPT-3.5** â€“ generaciÃ³n + clasificaciÃ³n
* **OpenAI Embeddings** â€“ similitud semÃ¡ntica
* **LangChain** â€“ pipelines RAG
* **ChromaDB** â€“ vector store persistente
* **SQLite** â€“ feedback learning
* **scikit-learn** â€“ similitud coseno
* **Flask-CORS** â€“ soporte para Flutter
